Що таке MapReduce?
Паралельні обчислення дозволяють програмам використовувати кілька процесорів (або комп'ютерів) для виконання обчислень паралельно,
що може значно зменшити загальний час виконання. Це тема, яка відкриває двері до розуміння того, як можна ефективно обробляти великі обсяги даних
та виконувати складні обчислення швидше, використовуючи кілька обчислювальних ресурсів одночасно.

Паралельні обчислення тісно пов'язані з поняттями багатопотоковості та багатопроцесорності, які ми пройшли в попередньому розділі,
та є ключовими концепціями в галузі високопродуктивних обчислень. Багатопотоковість ефективна для задач, які вимагають одночасного виконання кількох операцій,
таких як графічний інтерфейс користувача та фонове завантаження даних. Використання багатопроцесорності дозволяє програмам значно збільшити обчислювальну
потужність за рахунок паралельної обробки даних або задач.


Ідея одночасного виконання кількох обчислень полягає в тому, що паралелізм 
може бути реалізований на рівні даних, коли одна й та сама операція виконується над різними частинами даних, або на рівні задач,
коли різні обчислення виконуються паралельно.

MapReduce є відомим прикладом паралельних обчислень, особливо в контексті обробки великих даних. 
Це програмна модель, розроблена Google для спрощення обробки великих наборів даних на великих кластерах надійних недорогих комп'ютерів.
Ця модель організована навколо двох основних функцій: map ("Map" — мапінг) та reduce ("Reduce" — редукція).

Фаза "Map" виконується паралельно на різних вузлах обчислювального кластера і передбачає виконання певного завдання для кожного вхідного елемента даних.
Це може включати в себе фільтрацію, вибірку або перетворення даних. У цьому кроці вхідний набір даних перетворюється на інший набір даних, 
де кожен елемент розбивається на пари ключ-значення.

Після завершення фази "Map" виконується фаза "Reduce". У цій фазі результати обробки з фази "Map" об'єднуються та агрегуються 
для отримання кінцевого результату. Зазвичай у цій фазі виконуються операції групування, сортування та обчислення підсумків.

Головна перевага використання MapReduce — це те, що він дозволяє обробляти датасети розміром у терабайти або навіть петабайти, 
розподіляючи обробку на сотні або тисячі машин у кластері.

В архітектурі MapReduce існує ще фаза "Shuffle" — це проміжний крок між фазами "Map" і "Reduce". 
Після виконання фази "Map", вихідні дані мапера (Mapper) розподіляються та сортуються перед тим, як передавати їх до фази "Reduce".



Отже, підсумуємо, що основні етапи MapReduce — це Map, Shuffle та Reduce:

Map — незалежна обробка частин даних паралельно, кожен мапер працює із власним сегментом вхідних даних.
Shuffle — організація та групування проміжних результатів із різних маперів для подальшої обробки.
Reduce — агрегація результатів із різних маперів, кожен ред’юсер може працювати паралельно, обробляючи дані з власного набору ключів.